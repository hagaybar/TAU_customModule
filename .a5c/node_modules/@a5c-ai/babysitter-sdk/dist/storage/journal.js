"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.appendEvent = appendEvent;
exports.loadJournal = loadJournal;
const fs_1 = require("fs");
const path_1 = __importDefault(require("path"));
const crypto_1 = __importDefault(require("crypto"));
const paths_1 = require("./paths");
const atomic_1 = require("./atomic");
const ulids_1 = require("./ulids");
const clock_1 = require("./clock");
function formatSeq(seq) {
    return seq.toString().padStart(6, "0");
}
async function getExistingSeqs(journalDir) {
    try {
        const entries = await fs_1.promises.readdir(journalDir);
        return entries
            .map((name) => Number(name.split(".")[0]))
            .filter((n) => Number.isFinite(n));
    }
    catch (error) {
        const err = error;
        if (err.code === "ENOENT")
            return [];
        throw error;
    }
}
async function appendEvent(opts) {
    const journalDir = (0, paths_1.getJournalDir)(opts.runDir);
    await fs_1.promises.mkdir(journalDir, { recursive: true });
    const seqs = await getExistingSeqs(journalDir);
    const seq = (seqs.length ? Math.max(...seqs) : 0) + 1;
    const ulid = (0, ulids_1.nextUlid)();
    const filename = `${formatSeq(seq)}.${ulid}.json`;
    const recordedAt = (0, clock_1.getClockIsoString)();
    const eventPayload = {
        type: opts.eventType,
        recordedAt,
        data: opts.event,
    };
    const contents = JSON.stringify(eventPayload, null, 2) + "\n";
    const checksum = crypto_1.default.createHash("sha256").update(contents).digest("hex");
    const payloadWithChecksum = JSON.stringify({ ...eventPayload, checksum }, null, 2) + "\n";
    const targetPath = path_1.default.join(journalDir, filename);
    await (0, atomic_1.writeFileAtomic)(targetPath, payloadWithChecksum);
    return { seq, ulid, filename, checksum, path: targetPath, recordedAt };
}
function parseJournalFilename(filename) {
    const [seqPart, ulidPart] = filename.replace(/\.json$/i, "").split(".");
    const seq = Number(seqPart);
    if (!Number.isFinite(seq) || !ulidPart) {
        throw new Error(`Invalid journal filename: ${filename}`);
    }
    return { seq, ulid: ulidPart };
}
async function loadJournal(runDir) {
    const journalDir = (0, paths_1.getJournalDir)(runDir);
    try {
        const entries = await fs_1.promises.readdir(journalDir);
        const sorted = entries
            .filter((name) => name.endsWith(".json"))
            .sort();
        const events = [];
        for (const file of sorted) {
            const { seq, ulid } = parseJournalFilename(file);
            const fullPath = path_1.default.join(journalDir, file);
            const raw = await parseJournalFile(fullPath);
            events.push({
                seq,
                ulid,
                filename: file,
                path: fullPath,
                type: raw.type ?? "UNKNOWN",
                recordedAt: typeof raw.recordedAt === "string" ? raw.recordedAt : (0, clock_1.getClockIsoString)(),
                data: raw.data ?? {},
                checksum: typeof raw.checksum === "string" ? raw.checksum : undefined,
            });
        }
        return events;
    }
    catch (error) {
        const err = error;
        if (err.code === "ENOENT")
            return [];
        throw error;
    }
}
async function parseJournalFile(fullPath) {
    const contents = await fs_1.promises.readFile(fullPath, "utf8");
    try {
        return JSON.parse(contents);
    }
    catch (error) {
        const parseError = new Error(`Failed to parse journal file ${fullPath}: ${error.message}`);
        parseError.code = "JOURNAL_PARSE_FAILED";
        parseError.path = fullPath;
        throw parseError;
    }
}
